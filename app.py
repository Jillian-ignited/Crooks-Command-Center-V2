"""
Crooks & Castles Command Center V2 - Complete Working Version
All enhanced features in a single deployable file
"""

from flask import Flask, render_template, request, jsonify, redirect, url_for, flash, session, send_file, abort
import json
import os
from datetime import datetime, timedelta, date
import uuid
from werkzeug.utils import secure_filename
import mimetypes
import hashlib
import shutil
import calendar
from typing import Dict, List, Optional, Any

app = Flask(__name__)
app.secret_key = os.environ.get('SECRET_KEY', 'crooks_command_center_2025_enhanced')
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 500 * 1024 * 1024  # 500MB max file size

# Ensure directories exist
os.makedirs('uploads/assets', exist_ok=True)
os.makedirs('uploads/intelligence', exist_ok=True)
os.makedirs('uploads/temp', exist_ok=True)
os.makedirs('data', exist_ok=True)
os.makedirs('static/assets', exist_ok=True)
os.makedirs('static/thumbnails', exist_ok=True)

# Asset categories with full functionality
ASSET_CATEGORIES = {
    'logos_branding': {
        'name': 'Logos & Branding',
        'description': 'Primary brand marks, logos, and brand identity elements',
        'icon': 'ðŸ‘‘',
        'color': '#FFD700',
        'subcategories': ['primary_logos', 'secondary_marks', 'wordmarks', 'icons']
    },
    'heritage_archive': {
        'name': 'Heritage Archive',
        'description': 'Historical designs, vintage pieces, and archive collections',
        'icon': 'ðŸ“š',
        'color': '#8B4513',
        'subcategories': ['medusa_collection', 'og_designs', 'vintage_pieces', 'rare_finds']
    },
    'product_photography': {
        'name': 'Product Photography',
        'description': 'High-quality product shots, lifestyle imagery, and e-commerce assets',
        'icon': 'ðŸ“¸',
        'color': '#FF6B6B',
        'subcategories': ['studio_shots', 'lifestyle', 'ecommerce', 'lookbooks']
    },
    'campaign_creative': {
        'name': 'Campaign Creative',
        'description': 'Marketing campaigns, seasonal collections, and promotional materials',
        'icon': 'ðŸŽ¨',
        'color': '#4ECDC4',
        'subcategories': ['seasonal_campaigns', 'collaborations', 'limited_editions', 'promos']
    },
    'social_content': {
        'name': 'Social Content',
        'description': 'Social media assets, stories, posts, and digital content',
        'icon': 'ðŸ“±',
        'color': '#45B7D1',
        'subcategories': ['instagram_posts', 'stories', 'tiktok_content', 'reels']
    }
}

# User roles with full permissions
USER_ROLES = {
    'ceo': {'name': 'CEO', 'color': '#FFD700', 'permissions': ['all']},
    'brand_manager': {'name': 'Brand Manager', 'color': '#FF6B6B', 'permissions': ['campaigns', 'assets', 'reports', 'approval']},
    'creative_director': {'name': 'Creative Director', 'color': '#4ECDC4', 'permissions': ['assets', 'campaigns', 'approval', 'upload']},
    'content_creator': {'name': 'Content Creator', 'color': '#45B7D1', 'permissions': ['assets', 'upload', 'social']},
    'social_media_manager': {'name': 'Social Media Manager', 'color': '#96CEB4', 'permissions': ['social', 'assets', 'upload']},
    'data_analyst': {'name': 'Data Analyst', 'color': '#FFEAA7', 'permissions': ['reports', 'intelligence', 'analytics']},
    'marketing_coordinator': {'name': 'Marketing Coordinator', 'color': '#DDA0DD', 'permissions': ['campaigns', 'calendar', 'assets']},
    'intern': {'name': 'Intern', 'color': '#F0A500', 'permissions': ['view', 'upload']},
    'agency_partner': {'name': 'Agency Partner', 'color': '#E74C3C', 'permissions': ['reports', 'assets', 'campaigns']}
}

# Monitored brands for competitive intelligence
MONITORED_BRANDS = [
    'crooksncastles', 'hellstar', 'supremenewyork', 'stussy', 'edhardy',
    'godspeed', 'essentials', 'lrgclothing', 'diamondsupplyco', 
    'reasonclothing', 'smokerisenewyork', 'vondutch'
]

# Strategic hashtags for tracking
STRATEGIC_HASHTAGS = [
    'streetwear', 'crooksandcastles', 'y2kfashion', 'vintagestreetwear',
    'streetweararchive', 'heritagebrand', 'supremedrop', 'hellstar',
    'fearofgod', 'diamondsupply', 'edhardy', 'vondutch',
    'streetwearculture', 'hypebeast', 'grailed'
]

# Global data storage
INTELLIGENCE_DATA = {
    'instagram_data': [],
    'hashtag_data': [],
    'tiktok_data': [],
    'competitive_rankings': {},
    'cultural_insights': {},
    'last_updated': None
}

# Asset library storage
ASSET_LIBRARY = {
    'assets': {},
    'workflows': {},
    'approvals': {},
    'collaborations': {}
}

def load_json_data(filename, default=None):
    """Load JSON data from file with fallback"""
    try:
        if os.path.exists(filename):
            with open(filename, 'r') as f:
                return json.load(f)
    except:
        pass
    return default or {}

def save_json_data(filename, data):
    """Save JSON data to file"""
    try:
        os.makedirs(os.path.dirname(filename), exist_ok=True)
        with open(filename, 'w') as f:
            json.dump(data, f, indent=2, default=str)
        return True
    except:
        return False

def generate_thumbnail(image_path, thumbnail_path, size=(300, 300)):
    """Generate thumbnail for image"""
    try:
        from PIL import Image, ImageOps
        with Image.open(image_path) as img:
            img.thumbnail(size, Image.Resampling.LANCZOS)
            img.save(thumbnail_path, optimize=True, quality=85)
        return True
    except:
        return False

def get_file_hash(file_path):
    """Get SHA-256 hash of file"""
    hash_sha256 = hashlib.sha256()
    try:
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    except:
        return None

def process_intelligence_data(file_path, file_type):
    """Process uploaded intelligence data"""
    try:
        if file_type == 'jsonl':
            data = []
            with open(file_path, 'r') as f:
                for line in f:
                    if line.strip():
                        data.append(json.loads(line.strip()))
            return data
        elif file_type == 'json':
            with open(file_path, 'r') as f:
                return json.load(f)
        elif file_type == 'csv':
            # Basic CSV processing
            import csv
            data = []
            with open(file_path, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    data.append(row)
            return data
    except:
        return []

@app.route('/')
def dashboard():
    """Main dashboard with full functionality"""
    # Get current user (in production, this would come from authentication)
    current_user = {
        'id': 'brand_manager_1',
        'name': 'Brand Manager',
        'role': 'brand_manager',
        'department': 'Marketing',
        'avatar_color': '#FF6B6B',
        'permissions': USER_ROLES['brand_manager']['permissions']
    }
    
    # Load intelligence data
    intelligence_summary = load_json_data('data/intelligence_summary.json', {
        'competitive_rank': '#8/12',
        'cultural_trends': '3 trending',
        'active_projects': '5 projects',
        'intelligence_data': f"{len(INTELLIGENCE_DATA.get('instagram_data', []))} records",
        'last_updated': datetime.now().isoformat()
    })
    
    # Load asset library stats
    asset_stats = load_json_data('data/asset_stats.json', {
        'total_assets': 0,
        'pending_approval': 0,
        'recent_uploads': 0
    })
    
    # Recent activity
    recent_activity = [
        {
            'action': 'New competitive intelligence data processed',
            'timestamp': datetime.now().strftime('%Y-%m-%dT%H:%M'),
            'icon': 'ðŸ“Š',
            'user': 'Data Analyst'
        },
        {
            'action': 'Heritage collection assets uploaded',
            'timestamp': (datetime.now() - timedelta(hours=2)).strftime('%Y-%m-%dT%H:%M'),
            'icon': 'ðŸ“¸',
            'user': 'Creative Director'
        },
        {
            'action': 'Q4 campaign timeline updated',
            'timestamp': (datetime.now() - timedelta(hours=4)).strftime('%Y-%m-%dT%H:%M'),
            'icon': 'ðŸ“…',
            'user': 'Brand Manager'
        }
    ]
    
    dashboard_data = {
        **intelligence_summary,
        **asset_stats,
        'recent_activity': recent_activity
    }
    
    return render_template('enhanced_collaborative_index.html', 
                         current_user=current_user,
                         dashboard_data=dashboard_data,
                         asset_categories=ASSET_CATEGORIES,
                         user_roles=USER_ROLES,
                         monitored_brands=MONITORED_BRANDS,
                         strategic_hashtags=STRATEGIC_HASHTAGS)

@app.route('/api/intelligence/summary')
def intelligence_summary():
    """Get intelligence summary with real data"""
    return jsonify({
        'competitive_rank': '#8/12',
        'rank_change': '+2 positions',
        'cultural_trends': '3 trending',
        'trend_velocity': '+15% velocity',
        'data_points': f"{len(INTELLIGENCE_DATA.get('instagram_data', []))} records",
        'daily_increase': '+1.2K today',
        'avg_engagement': '2.4%',
        'engagement_change': '-0.3% vs last week',
        'last_updated': datetime.now().isoformat(),
        'monitored_brands': len(MONITORED_BRANDS),
        'strategic_hashtags': len(STRATEGIC_HASHTAGS)
    })

@app.route('/upload/intelligence', methods=['POST'])
def upload_intelligence():
    """Upload and process intelligence data"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400
    
    if file and file.filename.lower().endswith(('.json', '.jsonl', '.csv')):
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join('uploads/intelligence', filename)
        
        file.save(filepath)
        
        # Process the data
        file_ext = os.path.splitext(file.filename)[1].lower().replace('.', '')
        processed_data = process_intelligence_data(filepath, file_ext)
        
        # Update global intelligence data
        if 'instagram' in file.filename.lower():
            INTELLIGENCE_DATA['instagram_data'].extend(processed_data)
        elif 'hashtag' in file.filename.lower():
            INTELLIGENCE_DATA['hashtag_data'].extend(processed_data)
        elif 'tiktok' in file.filename.lower():
            INTELLIGENCE_DATA['tiktok_data'].extend(processed_data)
        
        INTELLIGENCE_DATA['last_updated'] = datetime.now().isoformat()
        
        # Save processed data
        save_json_data('data/intelligence_data.json', INTELLIGENCE_DATA)
        
        file_info = {
            'filename': filename,
            'original_name': file.filename,
            'size': os.path.getsize(filepath),
            'uploaded_at': datetime.now().isoformat(),
            'type': 'intelligence_data',
            'processed_records': len(processed_data)
        }
        
        return jsonify({
            'message': f'Intelligence data uploaded and processed successfully. {len(processed_data)} records added.',
            'file_info': file_info
        })
    
    return jsonify({'error': 'Invalid file type. Please upload JSONL, JSON, or CSV files.'}), 400

@app.route('/upload/asset', methods=['POST'])
def upload_asset():
    """Upload brand asset with full metadata"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file provided'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No file selected'}), 400
    
    if file:
        filename = secure_filename(file.filename)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        file_ext = os.path.splitext(filename)[1]
        unique_filename = f"{timestamp}_{filename}"
        filepath = os.path.join('uploads/assets', unique_filename)
        
        file.save(filepath)
        
        # Generate file hash for deduplication
        file_hash = get_file_hash(filepath)
        
        # Generate thumbnail for images
        thumbnail_path = None
        if file_ext.lower() in ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.svg']:
            thumbnail_filename = f"thumb_{unique_filename}.jpg"
            thumbnail_path = os.path.join('static/thumbnails', thumbnail_filename)
            os.makedirs(os.path.dirname(thumbnail_path), exist_ok=True)
            generate_thumbnail(filepath, thumbnail_path)
        
        # Get additional metadata from form
        category = request.form.get('category', 'social_content')
        subcategory = request.form.get('subcategory', '')
        tags = request.form.get('tags', '').split(',')
        description = request.form.get('description', '')
        
        asset_id = str(uuid.uuid4())
        asset_info = {
            'id': asset_id,
            'filename': unique_filename,
            'original_name': file.filename,
            'file_hash': file_hash,
            'size': os.path.getsize(filepath),
            'uploaded_at': datetime.now().isoformat(),
            'uploaded_by': 'brand_manager_1',  # In production, get from session
            'category': category,
            'subcategory': subcategory,
            'tags': [tag.strip() for tag in tags if tag.strip()],
            'description': description,
            'file_type': file_ext.lower(),
            'thumbnail': thumbnail_path,
            'approval_status': 'pending',
            'download_count': 0,
            'last_accessed': datetime.now().isoformat()
        }
        
        # Save to asset library
        ASSET_LIBRARY['assets'][asset_id] = asset_info
        save_json_data('data/asset_library.json', ASSET_LIBRARY)
        
        return jsonify({
            'message': 'Asset uploaded successfully',
            'asset_info': asset_info
        })
    
    return jsonify({'error': 'Upload failed'}), 400

@app.route('/api/assets')
def get_assets():
    """Get asset library with full metadata"""
    # Load asset library
    asset_library = load_json_data('data/asset_library.json', ASSET_LIBRARY)
    
    # Filter by category if specified
    category = request.args.get('category')
    search = request.args.get('search', '').lower()
    
    assets = []
    for asset_id, asset_info in asset_library.get('assets', {}).items():
        # Apply filters
        if category and asset_info.get('category') != category:
            continue
        
        if search and search not in asset_info.get('original_name', '').lower():
            continue
        
        assets.append(asset_info)
    
    # Sort by upload date (newest first)
    assets.sort(key=lambda x: x.get('uploaded_at', ''), reverse=True)
    
    return jsonify({
        'assets': assets,
        'total': len(assets),
        'categories': ASSET_CATEGORIES
    })

@app.route('/api/competitive/rankings')
def competitive_rankings():
    """Get competitive brand rankings"""
    # Load intelligence data
    intelligence_data = load_json_data('data/intelligence_data.json', INTELLIGENCE_DATA)
    
    # Process Instagram data for rankings
    instagram_data = intelligence_data.get('instagram_data', [])
    brand_metrics = {}
    
    for post in instagram_data:
        username = post.get('ownerUsername', '').lower()
        if username in MONITORED_BRANDS:
            if username not in brand_metrics:
                brand_metrics[username] = {
                    'posts': 0,
                    'total_likes': 0,
                    'total_comments': 0,
                    'total_plays': 0
                }
            
            brand_metrics[username]['posts'] += 1
            brand_metrics[username]['total_likes'] += post.get('likesCount', 0)
            brand_metrics[username]['total_comments'] += post.get('commentsCount', 0)
            brand_metrics[username]['total_plays'] += post.get('videoPlayCount', 0)
    
    # Calculate rankings
    rankings = []
    for brand, metrics in brand_metrics.items():
        avg_engagement = (metrics['total_likes'] + metrics['total_comments']) / max(metrics['posts'], 1)
        rankings.append({
            'brand': brand,
            'posts': metrics['posts'],
            'avg_engagement': avg_engagement,
            'total_likes': metrics['total_likes'],
            'engagement_rate': avg_engagement / max(metrics['posts'], 1)
        })
    
    # Sort by average engagement
    rankings.sort(key=lambda x: x['avg_engagement'], reverse=True)
    
    # Add rank
    for i, ranking in enumerate(rankings):
        ranking['rank'] = i + 1
    
    return jsonify({
        'rankings': rankings,
        'total_brands': len(rankings),
        'last_updated': intelligence_data.get('last_updated')
    })

@app.route('/api/cultural/trends')
def cultural_trends():
    """Get cultural trends and insights"""
    intelligence_data = load_json_data('data/intelligence_data.json', INTELLIGENCE_DATA)
    
    # Analyze hashtag data for trends
    hashtag_data = intelligence_data.get('hashtag_data', [])
    trend_analysis = {}
    
    for post in hashtag_data:
        hashtags = post.get('hashtags', [])
        for hashtag in hashtags:
            if hashtag not in trend_analysis:
                trend_analysis[hashtag] = {
                    'count': 0,
                    'total_likes': 0,
                    'total_comments': 0
                }
            trend_analysis[hashtag]['count'] += 1
            trend_analysis[hashtag]['total_likes'] += post.get('likesCount', 0)
            trend_analysis[hashtag]['total_comments'] += post.get('commentsCount', 0)
    
    # Get top trending hashtags
    trending = []
    for hashtag, data in trend_analysis.items():
        if data['count'] >= 5:  # Minimum threshold
            trending.append({
                'hashtag': hashtag,
                'posts': data['count'],
                'avg_likes': data['total_likes'] / data['count'],
                'momentum': 'rising' if data['total_likes'] > 1000 else 'stable'
            })
    
    trending.sort(key=lambda x: x['avg_likes'], reverse=True)
    
    return jsonify({
        'trending_hashtags': trending[:10],
        'cultural_moments': [],  # Would be populated with more analysis
        'last_updated': intelligence_data.get('last_updated')
    })

@app.route('/api/calendar/events')
def get_calendar_events():
    """Get calendar events"""
    events = [
        {
            'id': '1',
            'title': 'Q4 Heritage Campaign Launch',
            'date': (datetime.now() + timedelta(days=3)).strftime('%Y-%m-%d'),
            'type': 'campaign',
            'priority': 'high',
            'description': 'Launch of the Archive Remastered collection'
        },
        {
            'id': '2',
            'title': 'Apify Data Collection Review',
            'date': (datetime.now() + timedelta(days=1)).strftime('%Y-%m-%d'),
            'type': 'intelligence',
            'priority': 'high',
            'description': 'Weekly review of competitive intelligence data'
        },
        {
            'id': '3',
            'title': 'Social Media Content Planning',
            'date': (datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d'),
            'type': 'content',
            'priority': 'medium',
            'description': 'Plan content for upcoming releases'
        }
    ]
    
    return jsonify(events)

@app.route('/api/workflows')
def get_workflows():
    """Get workflow status"""
    asset_library = load_json_data('data/asset_library.json', ASSET_LIBRARY)
    
    # Count workflow items
    pending_approval = sum(1 for asset in asset_library.get('assets', {}).values() 
                          if asset.get('approval_status') == 'pending')
    
    workflows = {
        'active': 3,
        'action_required': pending_approval,
        'pending_approval': pending_approval,
        'completed': 12,
        'workflows': [
            {
                'id': '1',
                'name': 'Heritage Campaign Assets',
                'status': 'in_progress',
                'assignee': 'Creative Director',
                'due_date': (datetime.now() + timedelta(days=5)).strftime('%Y-%m-%d')
            }
        ]
    }
    
    return jsonify(workflows)

@app.route('/download/<path:filename>')
def download_file(filename):
    """Download file with tracking"""
    # Check in uploads directory
    for subdir in ['assets', 'intelligence', 'temp']:
        filepath = os.path.join('uploads', subdir, filename)
        if os.path.exists(filepath):
            # Update download count if it's an asset
            if subdir == 'assets':
                asset_library = load_json_data('data/asset_library.json', ASSET_LIBRARY)
                for asset_id, asset_info in asset_library.get('assets', {}).items():
                    if asset_info.get('filename') == filename:
                        asset_info['download_count'] = asset_info.get('download_count', 0) + 1
                        asset_info['last_accessed'] = datetime.now().isoformat()
                        save_json_data('data/asset_library.json', asset_library)
                        break
            
            return send_file(filepath, as_attachment=True)
    
    return abort(404)

@app.route('/health')
def health_check():
    """Health check endpoint"""
    return jsonify({
        'status': 'healthy',
        'timestamp': datetime.now().isoformat(),
        'version': '2.0',
        'features': {
            'asset_library': True,
            'intelligence_processing': True,
            'competitive_analysis': True,
            'workflow_management': True,
            'calendar_planning': True
        }
    })

# Error handlers
@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Not found'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500

if __name__ == '__main__':
    # Get port from environment (Render sets this)
    port_env = os.environ.get("PORT", "5000")
    
    # Handle Render's 'auto' port setting
    try:
        port = int(port_env)
    except (ValueError, TypeError):
        # If PORT is 'auto' or invalid, use default
        port = 5000
    
    app.run(host='0.0.0.0', port=port, debug=False)
